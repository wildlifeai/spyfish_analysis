{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4bd75b-c68f-45e3-a2b0-ed7d4077ff92",
   "metadata": {},
   "source": [
    "# Extract metadata from files\n",
    "\n",
    "\n",
    "This notebook offers visual and step by step review of the various BUV metadata files. \n",
    "\n",
    "When run it will go through each file and show the various options for each column, allowing to see how many different options there are. \n",
    "\n",
    "\n",
    "Running the export function will create an export folder in the current directory, with a file containing a row for each reviewed metadata file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c496254-54d7-4534-b289-037818b1c722",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7352db05-8441-4bac-86dd-cfa92a3f0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69f9e17-811b-47d6-bddf-edd470e432ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# NotPresent is the value generated when there is no value the spreadsheet, this is to distinguish from given NA values\n",
    "NA_VAL = \"NotPresent\"\n",
    "\n",
    "# SAMPLE_SHEET_LINES defines how many sample lines get printed out in the output each time a new file is processed\n",
    "SAMPLE_SHEET_LINES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965abe34-629f-4637-9014-8c87e176019f",
   "metadata": {},
   "source": [
    "#### Relevant Columns \n",
    "Check if these make sense.\n",
    "\n",
    "These columns will be reviewed and transferred into the export excel sheet.\n",
    "\n",
    "In the export excel sheet, FileName column is added to the start of the row\n",
    "\n",
    "The columns marked as duplicates are columns that appear in the sheets, but not in the surveys_buv_doc file but they seem to refer to the same thing.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271478c2-bc02-458e-bd71-f4a8bf1cffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"SurveyID\", # changed the order to SurveyID to know right away if it's multiple surveys or not\n",
    "           \"SurveyName\",\n",
    "           \"EncoderName\", # duplicate to Encoder\n",
    "           \"Encoder\", \n",
    "           \"DateEntry\",\n",
    "           \"OfficeContact\",\n",
    "           \"LinkToMarineReserve\", # duplicate to Reserve\n",
    "           \"Reserve\", \n",
    "           \"Region\",\n",
    "           \"SurveyLocationAcronym\", # duplicate to ReserveCode\n",
    "           \"ReserveCode\", \n",
    "           \"SurveyStartDate\",\n",
    "           \"ContractorName\",\n",
    "           \"ContractNumber\",\n",
    "           \"SurveyLeaderName\",\n",
    "           \"StratifiedBy\",\n",
    "           \"SiteSelectionDesign\",\n",
    "           \"SurveyVerbatim\",\n",
    "           \"FishMultiSpecies\",\n",
    "           \"IsLongTermMonitoring\",\n",
    "           \"RightsHolder\",\n",
    "           \"RecordType\",\n",
    "           \"IsMoreHabitatData\",\n",
    "           \"LinkToContract\",\n",
    "           \"LinkReport01\",\n",
    "           \"LinkToOriginalData\",\n",
    "           \"Vessel\",\n",
    "           \"BaitSpecies\",\n",
    "           \"BaitAmount\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e8c919-ac22-4658-a482-bebc884b1ea0",
   "metadata": {},
   "source": [
    "#### Current placeholder values for columns with no entries. \n",
    "Commented out ones will default to NA_VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e7446b3-b877-4192-bfc1-c995105ebf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_cell_solutions = {\n",
    "# \"SurveyName\",\n",
    "# \"Encoder\", # EncoderName?\n",
    "# \"DateEntry\",\n",
    "# \"OfficeContact\",\n",
    "# \"Reserve\", # LinkToMarineReserve?\n",
    "# \"Region\",\n",
    "# \"ReserveCode\", # SurveyLocationAcronym? first 3 letters of SurveyID\n",
    "# \"SurveyID\",\n",
    "# \"SurveyStartDate\",\n",
    "# \"ContractorName\",\n",
    "# \"ContractNumber\",\n",
    "# \"SurveyLeaderName\",\n",
    "# \"StratifiedBy\": \"check with Mon\", \n",
    "\"SiteSelectionDesign\": \"Non-random\", \n",
    "# \"SurveyVerbatim\": NA_VAL,\n",
    "\"FishMultiSpecies\": \"TRUE\", \n",
    "# \"IsLongTermMonitoring\",\n",
    "# \"RightsHolder\", \n",
    "\"RecordType\": \"FISH\",\n",
    "\"IsMoreHabitatData\": \"TRUE\", \n",
    "# \"LinkToContract\",\n",
    "# \"LinkReport01\" : NA_VAL,\n",
    "# \"LinkToOriginalData\": the number at the end of the filename - done in code \n",
    "\"Vessel\": NA_VAL,\n",
    "\"BaitSpecies\" : \"pilchard\",\n",
    "\"BaitAmount\": NA_VAL,\n",
    "# Survey Name\": This entry was removed\n",
    "}\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ac8e2-744a-4714-8266-16af8d98d72f",
   "metadata": {},
   "source": [
    "#### Select folder containing the files from which to extract metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d997251f-7a71-42d0-8fcc-5b1915bc2022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder_chooser = FileChooser(title='<b>Select a folder</b>')\n",
    "display(folder_chooser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b254940-f2cb-4452-8950-8582316d5178",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_folder = folder_chooser.selected_path\n",
    "assert selected_folder != None, \"Select folder in the cell above.\"\n",
    "print(f\"The selected folder is {selected_folder}\")\n",
    "all_files = os.listdir(selected_folder)\n",
    "all_tab_files = [os.path.join(selected_folder, file) for file in all_files if file.endswith(\".xlsx\") or file.endswith(\".xls\") or file.endswith(\".csv\")]\n",
    "all_tab_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0fd328-8a28-496f-a806-b2271758e096",
   "metadata": {},
   "source": [
    "## Main function to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50680390-644f-4f95-b4d7-bca6a2303874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def export_metadata_from_files_to_excel(all_tab_files, columns, export_excel_file_name=None, sheet_name=\"BUV\"):\n",
    "    print(f\"Exporting following files:\\n{all_tab_files}\")\n",
    "    \n",
    "    problem_files = []\n",
    "    list_of_metadata = []\n",
    "    df_with_vals = pd.DataFrame()\n",
    "\n",
    "    \n",
    "    for file_name in all_tab_files:\n",
    "        print(f\"Working on file: '{file_name}'. Example rows:\\n\")\n",
    "\n",
    "        # Extract data frame from Excel sheet\n",
    "        current_file_df = get_df_from_sheet(file_name, sheet_name)\n",
    "        if current_file_df.empty:\n",
    "            print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!File not exported {file_name}!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            problem_files.append(file_name)\n",
    "            continue\n",
    "\n",
    "        # Display sample of data frame\n",
    "        with pd.option_context('display.max_columns', None): \n",
    "            display(current_file_df.sample(min(SAMPLE_SHEET_LINES, current_file_df.shape[0])))\n",
    "\n",
    "\n",
    "        # Create row with metadata\n",
    "        file_metadata = [file_name]\n",
    "        for column in columns:\n",
    "            col_vals = current_file_df.get(column, pd.Series())\n",
    "            column_val = extract_val(col_vals, column, file_name)\n",
    "            file_metadata.append(column_val)\n",
    "        list_of_metadata.append(file_metadata)\n",
    "\n",
    "        # Export extracted metadata to Excel sheet in export folder\n",
    "        # rewrite at each step to save progress after each file\n",
    "        df_with_vals = pd.DataFrame(list_of_metadata, columns= [\"FileName\"] + columns)\n",
    "        if not export_excel_file_name:\n",
    "            export_excel_file_name = f\"surveys_buv_doc_{sheet_name}.xlsx\"\n",
    "            \n",
    "        # make export folder in folder containing all files\n",
    "        path_to_export = os.path.join(selected_folder, \"export\")\n",
    "        os.makedirs(path_to_export, exist_ok=True)\n",
    "        export_location = os.path.join(path_to_export, export_excel_file_name)\n",
    "        print(f\"Exporting data to file: '{export_location}'\")\n",
    "        df_with_vals.to_excel(export_location)  \n",
    "        \n",
    "    print(f\"Problem files: {problem_files}\")\n",
    "   \n",
    "    return df_with_vals, problem_files\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2dc2c0-4065-4547-a110-c818df2c801f",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ce5b87d-9f93-4361-bf49-5cb5d200f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_sheet(file_name, sheet_name):\n",
    "    \"\"\"Get a data frame from the given sheet and filename.\"\"\"\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        try: \n",
    "            return pd.read_csv(file_name)\n",
    "        except: \n",
    "            print(f\"Csv file {file_name} wasn't read.\")\n",
    "            return pd.DataFrame()\n",
    "    try: \n",
    "        return pd.read_excel(file_name, sheet_name=sheet_name)\n",
    "    except: \n",
    "        print(f\"File {file_name} has no {sheet_name} sheet, it will try to process the first sheet.\")\n",
    "    try: \n",
    "        return pd.read_excel(file_name)\n",
    "    except Exception as error:\n",
    "        print(\"File wasn't processed because of:\", error)\n",
    "        return pd.DataFrame()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be86468b-9938-4743-b339-479b0f1db41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_val(col_vals, column_name, file_name):\n",
    "    \"\"\"Extract value from column, populate for missing values.\"\"\"\n",
    "    # Populate for missing value\n",
    "    if col_vals.empty:   \n",
    "        print(f\"\\n{column_name} not present\")\n",
    "        unconfirmed_val = NA_VAL\n",
    "        if column_name in empty_cell_solutions:\n",
    "            unconfirmed_val = empty_cell_solutions[column_name]\n",
    "        elif column_name == \"LinkToOriginalData\":\n",
    "            unconfirmed_val = get_LinkToOriginalData(file_name)\n",
    "        print(f\"setting {column_name} as {unconfirmed_val}\")\n",
    "\n",
    "    # Extract values\n",
    "    elif not col_vals.empty:\n",
    "        unique_vals = list(col_vals.unique())\n",
    "        \n",
    "        # Add link to original data, as sometimes the value present in the cell doesn't make sense\n",
    "        if column_name == 'LinkToOriginalData':\n",
    "            link_val = get_LinkToOriginalData(file_name)\n",
    "            if link_val not in unique_vals:\n",
    "                unique_vals.append(link_val)\n",
    "            print(f\"If the 'LinkToOriginalData' entry doesn't make sense check the filename number after DOC-\")\n",
    "            \n",
    "        if len(unique_vals) > 1:\n",
    "            unconfirmed_val = deal_with_multiple_values(unique_vals, column_name)\n",
    "        else: \n",
    "            unconfirmed_val = unique_vals[0]\n",
    "      \n",
    "\n",
    "    # Confirm value\n",
    "    confirmed_val = confirm_val(unconfirmed_val, column_name)\n",
    "    return confirmed_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4d4fdf6-78e3-460c-9807-14608322dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LinkToOriginalData(file_name):\n",
    "    \"\"\"Get number at the end of filename that works as Link to Original Data\"\"\"\n",
    "    doc_num_start = file_name.find(\"DOC-\")\n",
    "    unconfirmed_val = NA_VAL\n",
    "    if doc_num_start != -1:\n",
    "        unconfirmed_val = file_name[doc_num_start+4:]\n",
    "        end_num = unconfirmed_val.find(\".\")\n",
    "        if end_num != -1:\n",
    "            unconfirmed_val = unconfirmed_val[:end_num]\n",
    "    return unconfirmed_val\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "505521d1-6d67-43a6-b650-54190acc20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_with_multiple_values(unique_vals, column_name):\n",
    "    \"\"\"Deal with the case when a column has multiple unique values.\"\"\"\n",
    "    print(f\"Multiple values in column {column_name}\")\n",
    "    for i, value in enumerate(unique_vals): \n",
    "        print(f\"{i+1}: {value}\")\n",
    "    print(\"\"\"\\nSelect the number in front of the correct value or\n",
    "a: if you want to write your entry or\n",
    "b: if you want to select all the values separated by a semicolon write.\n",
    "\\n\"\"\") \n",
    "    user_input = input(\"Enter your selection:\\n\")\n",
    "    val = False\n",
    "    while val is False:\n",
    "        if user_input.lower() == \"a\":\n",
    "            print(f\"Write your entry for column {column_name}:\\n\")\n",
    "            val = input(\"Write here:\\n\")\n",
    "        elif user_input.lower() == \"b\":\n",
    "            val = \";\".join(map(str, unique_vals))\n",
    "        elif not user_input.isdigit() or int(user_input) > len(unique_vals):\n",
    "            print(\"Invalid entry, select again:\\n\")\n",
    "            user_input = input(\"Enter your selection:\\n\")\n",
    "        else:\n",
    "            val = str(unique_vals[int(user_input)-1])\n",
    "    return val\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e4d8ca8-f4a3-44d3-9763-3ccdce565ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def confirm_val(unconfirmed_val, column_name):\n",
    "    \"\"\"Confirm the given value.\"\"\"\n",
    "    confirm = False\n",
    "    while not confirm:\n",
    "        print(f\"\\nThe value for {column_name} is:\\n{unconfirmed_val}\\nconfirm with 1 or add your value.\\n\")\n",
    "        user_input = input(\"Enter your selection:\\n\")\n",
    "        if user_input == \"1\":\n",
    "            confirm = True\n",
    "        else: \n",
    "            unconfirmed_val = user_input\n",
    "    return str(unconfirmed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c71189-dbb9-4952-a4f7-d77830d80261",
   "metadata": {},
   "source": [
    "# Run the function\n",
    "\n",
    "This goes through each file in the selected folder, and offers for selection unique entries for each column. If anything looks suspicious, review the file manually.\n",
    "\n",
    "Running the export function will create an export folder in the current directory, with a file containing a row for each reviewed metadata file. If you stop the function half way, the files that you have already processed have already been exported and have their corresponding row in the csv file in the export folder in your selected folder from above.\n",
    "\n",
    "Some things to note: \n",
    "- sometimes the files still include examples in the first lines, so make sure to check if that is the case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b445978-47bb-4b30-aa19-3766557bab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata, problem_files = export_metadata_from_files_to_excel(all_tab_files=all_tab_files, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efd1ff4-a1a5-4d7e-ab93-883c03c80700",
   "metadata": {},
   "source": [
    "## Print the created metadata dataframe (that was exported to the excel file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed8f20-e12a-46d3-9eae-ad107fd40595",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91f7ddd2-585e-4ff2-97e9-680662e7d4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbb5f1e1-debe-4a9e-a434-207c9eb01811",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Spaces were removed from the column names, and cases changed to match data files\n",
    "- Added FileName as a column\n",
    "- Created some columns to match the ones in the original files, it's easy to duplicate:  \n",
    "\n",
    "    - \"EncoderName\", # duplicate to Encoder \n",
    "    - \"LinkToMarineReserve\", # duplicate to Reserve \n",
    "    - \"SurveyLocationAcronym\", # duplicate to ReserveCode \n",
    "\n",
    "- SurveyLocationAcronym is the start of SurveyID\n",
    "- SurveyStartDate is the same as the one from SurveyID (didn't double check).\n",
    " \n",
    "- Some files have a few example rows on top, to check which values are given by that \n",
    "- if there are two SurveyIDs in the same file, one can only review one at a time, so either do it manually, or run the file a second time, this time choosing the second option\n",
    "- Some True and False are read as floats 1.0 and 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd3782-de94-412e-b9bf-f34213795945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
